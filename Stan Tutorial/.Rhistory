SE = sqrt(diag(solve(mle$hessian)))# output parameter SEs
Tvalue = mode/SE# output parameter T-values
ll = 2*mle$minimum# -2*log-likelihood
np = length(coef.vec)                    # number of parameters
AIC = 2*(mle$minimum + np)                  # calculates AIC
n = sum(NI*NT)                           # number of observations
BIC = 2*mle$minimum + np*log(n)            # calculates BIC
list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC)
write.csv(list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC), file = "3seg4.csv")
#library("arm")
#library("numDeriv")
## library("texreg")
NX = 2 #number of parameters per segment
NS = 2 #number of consumer segments
NJ = 2 #number of brands
NT = 10 #number of period
NI = 300 #number of people
data = matrix(scan("M:/A Master of Science in Marketing Sciences/Empirical Models in Marketing/Code/data2.txt"),5,NI*NT)
data = t(data)
#Data File data2.CSV
# Col1= Customer ID
# Col2 = Time period
# Col3 = choice 1 if choice brand A and 2 if chose brand B
# Col4-5 = prices for brand A and brand B, respectively
coef.vec = rnorm(3 * NS) #parameters to be estimated.
log.lik <- function(coef.vec,data,ns,nj,nt,ni,nx)    #likelihood function
{
probability = exp(coef.vec[3*(1:(ns - 1))])/(1 + sum(exp(coef.vec[3*(1:(ns - 1))])))
prob = array(NA,nj)
overall = 0
## Individual
for (i in 1:ni)
{
## Segment
persontotal = 0
for (mj in 1:ns)
{
total = 1
## Time Series
for (k in 1:nt)
{
row = (i - 1) * nt + k
if (k == 1)
{
V1 = coef.vec[3*(mj - 1) + 1] + coef.vec[3*(mj - 1) + 2] * data[row,4]
# the systematic utility for 1
V2 = coef.vec[3*(mj - 1) + 2] * data[row,5]
# the systematic utility for 2
} else if (k != 1)
{
lag = coef.vec[3*ns]
V1 = coef.vec[3*(mj - 1) + 1] + coef.vec[3*(mj - 1) + 2] * data[row,4] + lag * as.numeric(data[row - 1,3] == 1)
# the systematic utility for 1
V2 = coef.vec[3*(mj - 1) + 2] * data[row,5] + lag * as.numeric(data[row - 1,3] == 2)
# the systematic utility for 2
}
prob[1] = exp(V1)/(exp(V1) + exp(V2))# logit for 1
prob[2] = exp(V2)/(exp(V1) + exp(V2))# logit for 2
choice = data[row,3]
total = total * prob[choice]
}
if (mj < ns)
{
persontotal = persontotal + probability[mj] * total
} else
{
persontotal = persontotal + (1 - sum(probability)) * total
}
}
overall = overall + log(persontotal)
}
return(-overall)
}
# optimization procedure to calculate the MLE estimates
mle <- nlm(log.lik,coef.vec,data = data,ns = NS,nj = NJ,nt = NT,ni = NI,nx = NX, hessian = TRUE)
# calculating the Hessian to obtain stdev
mode = mle$estimate  # output parameter estimates
SE = sqrt(diag(solve(mle$hessian)))# output parameter SEs
Tvalue = mode/SE# output parameter T-values
ll = 2*mle$minimum# -2*log-likelihood
np = length(coef.vec)                    # number of parameters
AIC = 2*(mle$minimum + np)                  # calculates AIC
n = sum(NI*NT)                           # number of observations
BIC = 2*mle$minimum + np*log(n)            # calculates BIC
list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC)
write.csv(list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC), file = "02seg1.csv")
#library("arm")
#library("numDeriv")
## library("texreg")
NX = 2 #number of parameters per segment
NS = 2 #number of consumer segments
NJ = 2 #number of brands
NT = 10 #number of period
NI = 300 #number of people
data = matrix(scan("M:/A Master of Science in Marketing Sciences/Empirical Models in Marketing/Code/data2.txt"),5,NI*NT)
data = t(data)
#Data File data2.CSV
# Col1= Customer ID
# Col2 = Time period
# Col3 = choice 1 if choice brand A and 2 if chose brand B
# Col4-5 = prices for brand A and brand B, respectively
coef.vec = rnorm(3 * NS) #parameters to be estimated.
log.lik <- function(coef.vec,data,ns,nj,nt,ni,nx)    #likelihood function
{
probability = exp(coef.vec[3*(1:(ns - 1))])/(1 + sum(exp(coef.vec[3*(1:(ns - 1))])))
prob = array(NA,nj)
overall = 0
## Individual
for (i in 1:ni)
{
## Segment
persontotal = 0
for (mj in 1:ns)
{
total = 1
## Time Series
for (k in 1:nt)
{
row = (i - 1) * nt + k
if (k == 1)
{
V1 = coef.vec[3*(mj - 1) + 1] + coef.vec[3*(mj - 1) + 2] * data[row,4]
# the systematic utility for 1
V2 = coef.vec[3*(mj - 1) + 2] * data[row,5]
# the systematic utility for 2
} else if (k != 1)
{
lag = coef.vec[3*ns]
V1 = coef.vec[3*(mj - 1) + 1] + coef.vec[3*(mj - 1) + 2] * data[row,4] + lag * as.numeric(data[row - 1,3] == 1)
# the systematic utility for 1
V2 = coef.vec[3*(mj - 1) + 2] * data[row,5] + lag * as.numeric(data[row - 1,3] == 2)
# the systematic utility for 2
}
prob[1] = exp(V1)/(exp(V1) + exp(V2))# logit for 1
prob[2] = exp(V2)/(exp(V1) + exp(V2))# logit for 2
choice = data[row,3]
total = total * prob[choice]
}
if (mj < ns)
{
persontotal = persontotal + probability[mj] * total
} else
{
persontotal = persontotal + (1 - sum(probability)) * total
}
}
overall = overall + log(persontotal)
}
return(-overall)
}
# optimization procedure to calculate the MLE estimates
mle <- nlm(log.lik,coef.vec,data = data,ns = NS,nj = NJ,nt = NT,ni = NI,nx = NX, hessian = TRUE)
# calculating the Hessian to obtain stdev
mode = mle$estimate  # output parameter estimates
SE = sqrt(diag(solve(mle$hessian)))# output parameter SEs
Tvalue = mode/SE# output parameter T-values
ll = 2*mle$minimum# -2*log-likelihood
np = length(coef.vec)                    # number of parameters
AIC = 2*(mle$minimum + np)                  # calculates AIC
n = sum(NI*NT)                           # number of observations
BIC = 2*mle$minimum + np*log(n)            # calculates BIC
list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC)
write.csv(list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC), file = "02seg2.csv")
#library("arm")
#library("numDeriv")
## library("texreg")
NX = 2 #number of parameters per segment
NS = 2 #number of consumer segments
NJ = 2 #number of brands
NT = 10 #number of period
NI = 300 #number of people
data = matrix(scan("M:/A Master of Science in Marketing Sciences/Empirical Models in Marketing/Code/data2.txt"),5,NI*NT)
data = t(data)
#Data File data2.CSV
# Col1= Customer ID
# Col2 = Time period
# Col3 = choice 1 if choice brand A and 2 if chose brand B
# Col4-5 = prices for brand A and brand B, respectively
coef.vec = rnorm(3 * NS) #parameters to be estimated.
log.lik <- function(coef.vec,data,ns,nj,nt,ni,nx)    #likelihood function
{
probability = exp(coef.vec[3*(1:(ns - 1))])/(1 + sum(exp(coef.vec[3*(1:(ns - 1))])))
prob = array(NA,nj)
overall = 0
## Individual
for (i in 1:ni)
{
## Segment
persontotal = 0
for (mj in 1:ns)
{
total = 1
## Time Series
for (k in 1:nt)
{
row = (i - 1) * nt + k
if (k == 1)
{
V1 = coef.vec[3*(mj - 1) + 1] + coef.vec[3*(mj - 1) + 2] * data[row,4]
# the systematic utility for 1
V2 = coef.vec[3*(mj - 1) + 2] * data[row,5]
# the systematic utility for 2
} else if (k != 1)
{
lag = coef.vec[3*ns]
V1 = coef.vec[3*(mj - 1) + 1] + coef.vec[3*(mj - 1) + 2] * data[row,4] + lag * as.numeric(data[row - 1,3] == 1)
# the systematic utility for 1
V2 = coef.vec[3*(mj - 1) + 2] * data[row,5] + lag * as.numeric(data[row - 1,3] == 2)
# the systematic utility for 2
}
prob[1] = exp(V1)/(exp(V1) + exp(V2))# logit for 1
prob[2] = exp(V2)/(exp(V1) + exp(V2))# logit for 2
choice = data[row,3]
total = total * prob[choice]
}
if (mj < ns)
{
persontotal = persontotal + probability[mj] * total
} else
{
persontotal = persontotal + (1 - sum(probability)) * total
}
}
overall = overall + log(persontotal)
}
return(-overall)
}
# optimization procedure to calculate the MLE estimates
mle <- nlm(log.lik,coef.vec,data = data,ns = NS,nj = NJ,nt = NT,ni = NI,nx = NX, hessian = TRUE)
# calculating the Hessian to obtain stdev
mode = mle$estimate  # output parameter estimates
SE = sqrt(diag(solve(mle$hessian)))# output parameter SEs
Tvalue = mode/SE# output parameter T-values
ll = 2*mle$minimum# -2*log-likelihood
np = length(coef.vec)                    # number of parameters
AIC = 2*(mle$minimum + np)                  # calculates AIC
n = sum(NI*NT)                           # number of observations
BIC = 2*mle$minimum + np*log(n)            # calculates BIC
list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC)
write.csv(list(Estimate = mode,SE = SE,Tvalue = Tvalue,minus2ll = ll,AIC = AIC,BIC = BIC), file = "02seg3.csv")
rm(list = ls())
q()
library(ISLR)
library(glmnet)
install.packages("e1071")
library (e1071)
set.seed(10)
x = matrix(rnorm(20*2), ncol=2)
y = c(rep(-1,10),rep(1,10))
x[y==1,] = x[y==1,]+1
plot(x,col=(3-y))
dat=data.frame(x=x, y=as.factor(y))
svmfit=svm(y~. , data=dat, kernel="linear" , cost=10 , scale=FALSE)
plot(svmfit,dat)
dat
x
x[y==1,]
plot(x,col = (3-y))
3-y
plot(svmfit,dat)
summary(svmfit)
svmfit$index
set.seed(10)
tune.out=tune(svm,y~., data=dat,kernel="linear",              ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
summary(tune.out)
bestmod=tune.out$best.model
summary(bestmod)
xtest=matrix(rnorm(20*2),ncol=2)
ytest=sample(c(-1,1), 20 ,rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat=data.frame(x=xtest,y=as.factor(ytest))
ypred=predict(bestmod, testdat)
table(predict=ypred,truth=testdat$y)
testdat
set.seed(20)
x=matrix(rnorm(200*2),ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y=c(rep(1,150),rep(2,50))
dat=data.frame(x=x,y=as.factor(y))
plot(x,col=y)
train=sample(200,100)
svmfit=svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit, dat[train,])
svmfit
svmfit=svm(y~.,data=dat[train,],kernel="polymonial",gamma=1,cost=1)
plot(svmfit, dat[train,])
svmfit=svm(y~.,data=dat[train,],kernel="polynomial",gamma=1,cost=1)
plot(svmfit, dat[train,])
svmfit=svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit2=svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1e5)
plot(svmfit2, dat[train,])
set.seed(30)
tune.out=tune(svm,y~.,data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
plot(tune.out)
plot(tune.out, dat[train,])
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newdata=dat[-train,]))
set.seed(40)
x=rbind(x,matrix(rnorm(50*2),ncol=2))
y=c(y,rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat=data.frame(x=x,y=as.factor(y))
dat
par(mfrow=c(1,1))
plot(x,col=(y+1))
svmfit=svm(y~.,data=dat,kernel="radial",cost=10,gamma=1)
plot(svmfit,dat)
par(mfrow=c(1,2))
plot(x,col=(y+1))
svmfit=svm(y~.,data=dat,kernel="radial",cost=10,gamma=1)
plot(svmfit,dat)
tune.out=tune(svmfit,y~.,data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
tune.out=tune(svm,y~.,data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newdata=dat[-train,]))
summary(tune.out)
tune.out$best.model
svmfit=svm(y~.,data=dat,kernel="radial",cost=1,gamma=0.5)
plot(svmfit,dat)
dat[-train,]
test = dat[-train,]
plot(test)
plot(test$x.1,test$x.2,col = test$y + 100)
plot(test$x.1,test$x.2)
test$y
as.numeric(test$y)
plot(test$x.1,test$x.2,col = as.numeric(test$y)+100)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newdata=dat[-train,]))
predict(svmfit,test[,1:2])
pred = predict(svmfit,test[,1:2])
plot(pred$x.1,pred$x.2,col = as.numeric(pred$y)+100)
plot(test$x.1,test$x.2,col = as.numeric(pred$y)+100)
plot(test$x.1,test$x.2,col = as.numeric(pred)+100)
plot(test$x.1,test$x.2,col = as.numeric(test$y)+100)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newdata=dat[-train,]))
prediction = predict(svmfit,test[,1:2])
table(true=dat[-train,"y"],pred=prediction)
result = table(true=dat[-train,"y"],pred=prediction)
result
table(true=dat[-train,"y"],pred=prediction)
diag(result)
sum(diag(result))
sum(diag(result))/sum(result)
n <- 12000
p <- 10
set.seed(100)
x <- matrix(rnorm(n * p), ncol = p)
y <- as.factor(c(-1, 1)[as.numeric(apply(x^2, 1, sum) > 9.34) + 1])
data <- data.frame(y, x)
data
View(data)
train <- sample(1:n, 2000, FALSE)
data <- data.frame(y, x)
train <- sample(1:n, 2000, FALSE)
formula <- y ~ .
vardep <- data[ , as.character(formula[[2]])]
cntrl <- rpart.control(maxdepth = 1, minsplit = 0, cp = -1)
mfinal <- 400
data.boosting <- boosting(formula = formula, data = data[train, ], mfinal = mfinal, coeflearn = "Breiman", boos = TRUE, control = cntrl)
install.packages(adabag)
install.packages("adabag")
library(adabag)
cntrl <- rpart.control(maxdepth = 1, minsplit = 0, cp = -1)
mfinal <- 400
data.boosting <- boosting(formula = formula, data = data[train, ], mfinal = mfinal, coeflearn = "Breiman", boos = TRUE, control = cntrl)
data.boostingBreimanTrue <- data.boosting
table(data.boosting$class, vardep[train], dnn = c("Predicted Class", "Observed Class"))
data.predboost <- predict.boosting(data.boosting, newdata = data[-train,])
data.predboost$confusion
data.predboost$error
library(adabag)
formula <- y ~.-y
vardep <- data[ , as.character(formula[[2]])]
cntrl <- rpart.control(maxdepth = 1, minsplit = 0, cp = -1)
mfinal <- 400
data.boosting <- boosting(formula = formula,  data = mlmkt[train,], mfinal = mfinal, coeflearn = "Breiman", boos = TRUE, control = cntrl)
ginitree.pred <- predict(prune.ginitree,subscription.test,type = "class")
(13164 + 349)/15244
data.boosting$importance
Sys.getenv('PATH')
system('g++ -v')
system('where make')
rm(list = ls())
Sys.getenv("PATH")
system('g++ -v')
system('where make')
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR))
dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M))
file.create(M)
cat("\nCXXFLAGS=-O3 -Wno-unused-variable -Wno-unused-function",
file = M, sep = "\n", append = TRUE)
Sys.getenv("PATH")
cat('Sys.setenv(BINPREF = "D:/R/R-3.3.2/R-3.3.2/Rtools/mingw_$(WIN)/bin/")',file = file.path(Sys.getenv("HOME"), ".Rprofile"), sep = "\n", append = TRUE)
cat("\nCXXFLAGS += -flto -Wno-ignored-attributes -Wno-deprecated-declarations", file = M, sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
cat(M)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
fx( 2L, 5 )
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '	return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; ' )
fx( 2L, 5 )
fx <- inline::cxxfunction(
signature(x = "integer", y = "numeric" ) ,
'	return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; '
)
fx( 2L, 5 )
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , 'return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; ' )
Sys.getenv("PATH")
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" )， '	return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; ' )
Sys.getenv('PATH')
system(`where make`)
system('where make')
cat(readLines(M), sep = "\n")
cat("\nCXXFLAGS += -flto -Wno-ignored-attributes -Wno-deprecated-declarations",
file = M, sep = "\n", append = TRUE)
Sys.getenv('PATH')
cat('Sys.setenv(BINPREF = "D:/R/-3.3.2/R-3.3.2/Rtools/mingw_$(WIN)/bin/")', file = file.path(Sys.getenv("HOME"), ".Rprofile"),  sep = "\n", append = TRUE)
cat('Sys.setenv(BINPREF = "D:/R/R-3.3.2/R-3.3.2/Rtools/mingw_$(WIN)/bin/")', file = file.path(Sys.getenv("HOME"), ".Rprofile"), sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
getwd
getwd(0)
getwd()
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR))
dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M))
file.create(M)
cat("\nCXXFLAGS=-O3 -Wno-unused-variable -Wno-unused-function",
file = M, sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
cat(M)
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ), '	return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; ' )
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
system('g++ -v')
system('where make')
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '	return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; ' )
Sys.setenv(MAKEFLAGS = "-j4")
install.packages("rstan", type = "source")
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '	return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ; ' )
fx( 2L, 5 )
rm(list=ls())
library(boot) # inverse logit function
library(rstan)
library(ggplot2)
library(shinystan)
rstan_options(auto_write = TRUE)
library(MASS) # mvrnorm
set.seed(0)
N=200
X=rnorm(N)
alpha=-0.5
beta=2
sigma=0.5
Y=alpha+beta*X+rnorm(N,sd=sigma)
plot(X,Y)
data_list<-list(N=N,x=X,y=Y)
fit<-stan(file = "lin_reg.stan",data = data_list,chains = 1,iter = 1000)
print(fit)
traceplot(fit,pars=c("alpha","beta","sigma"))
set.seed(0)
N=200
X=rnorm(N)
alpha=-0.5
beta=2
sigma=0.5
Y=alpha+beta*X+rnorm(N,sd=sigma)
plot(X,Y)
data_list<-list(N=N,x=X,y=Y)
fit<-stan(file = "lin_reg.stan",data = data_list,chains = 1,iter = 1000)
print(fit)
traceplot(fit,pars=c("alpha","beta","sigma"))
set.seed(0)
N=200
X=rnorm(N)
alpha=-0.5
beta=2
sigma=0.5
Y=alpha+beta*X+rnorm(N,sd=sigma)
plot(X,Y)
data_list<-list(N=N,x=X,y=Y)
fit<-stan(file = "lin_reg.stan",data = data_list,chains = 1,iter = 1000)
print(fit)
traceplot(fit,pars=c("alpha","beta","sigma"))
setwd("M:/A Master of Science in Marketing Sciences/Empirical Models in Marketing/Stan Tutorial")
set.seed(0)
N=200
X=rnorm(N)
alpha=-0.5
beta=2
sigma=0.5
Y=alpha+beta*X+rnorm(N,sd=sigma)
plot(X,Y)
data_list<-list(N=N,x=X,y=Y)
fit<-stan(file = "lin_reg.stan",data = data_list,chains = 1,iter = 1000)
print(fit)
traceplot(fit,pars=c("alpha","beta","sigma"))
knitr::opts_chunk$set(echo = TRUE)
data_list<-list(N=N,x=X,y=Y)
fit<-stan(file = "lin_reg.stan",data = data_list,chains = 1,iter = 1000)
#fit<-stan(model_code = lin_reg_st,data = data_list,chains = 1,iter = 1000)
print(fit)
traceplot(fit,pars=c("alpha","beta","sigma"))
